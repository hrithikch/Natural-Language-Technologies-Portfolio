{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Wordnet is an organized database of english words that are arranged in a hierarchical structure according to their meaning. It includes the major parts of speech- nouns, verbs, adjectives, and adverbs- with their definitions and relationships to other words. The words are organized into sets of synonymous words, or synsets. The synsets are related in a tree structure, with the more specific a word is, the further it is down the tree. It has many functions that can be used to identify and understand the various relationships between words.\n"
      ],
      "metadata": {
        "id": "429m1zt6GTqH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9rYQ3GsFpPQ",
        "outputId": "1b3edf85-c683-4372-e110-781951e99067"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "from nltk.corpus import wordnet as wn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Noun car synsets:"
      ],
      "metadata": {
        "id": "4FLpYq89sB8P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(wn.synsets('car'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kreMI7MNhqeb",
        "outputId": "53460c72-dd24-4ab6-d84b-3fe1667127d0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Synset('car.n.01'), Synset('car.n.02'), Synset('car.n.03'), Synset('car.n.04'), Synset('cable_car.n.01')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Car synset 01 definition, examples, and lemmas:"
      ],
      "metadata": {
        "id": "aYNoNiMnsHvG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s1= wn.synsets('car')[0]\n",
        "print(s1)\n",
        "print(\"\\ncar.n.01 definition:\")\n",
        "print(s1.definition())\n",
        "print(\"\\ncar.n.01 examples:\")\n",
        "print(s1.examples())\n",
        "print(\"\\ncar.n.01 lemmas:\")\n",
        "print(s1.lemmas())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkQKG2NEh2JZ",
        "outputId": "20a378f3-f739-4e07-db96-6a20c1cb3753"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synset('car.n.01')\n",
            "\n",
            "car.n.01 definition:\n",
            "a motor vehicle with four wheels; usually propelled by an internal combustion engine\n",
            "\n",
            "car.n.01 examples:\n",
            "['he needs a car to get to work']\n",
            "\n",
            "car.n.01 lemmas:\n",
            "[Lemma('car.n.01.car'), Lemma('car.n.01.auto'), Lemma('car.n.01.automobile'), Lemma('car.n.01.machine'), Lemma('car.n.01.motorcar')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Car synset 01 hypernyms up to top:"
      ],
      "metadata": {
        "id": "R1fV_zoKsRK7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s1= wn.synsets('car')[0]\n",
        "print(\"car.n.01 hypernyms up to top:\")\n",
        "hyp = s1.hypernyms()[0]\n",
        "top = wn.synset('entity.n.01')\n",
        "while hyp:\n",
        "  print(hyp)\n",
        "  if hyp == top:\n",
        "    break\n",
        "  if hyp.hypernyms():\n",
        "    hyp = hyp.hypernyms()[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upKIphg6oZPG",
        "outputId": "1f31e03a-cfdd-4db5-baed-fe3414deccdc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "car.n.01 hypernyms up to top:\n",
            "Synset('motor_vehicle.n.01')\n",
            "Synset('self-propelled_vehicle.n.01')\n",
            "Synset('wheeled_vehicle.n.01')\n",
            "Synset('container.n.01')\n",
            "Synset('instrumentality.n.03')\n",
            "Synset('artifact.n.01')\n",
            "Synset('whole.n.02')\n",
            "Synset('object.n.01')\n",
            "Synset('physical_entity.n.01')\n",
            "Synset('entity.n.01')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nouns in wordnet are organized as a single large heirarchy, with the top being the most general word: entity. Each level down has many words that are related to the parent word but more specific."
      ],
      "metadata": {
        "id": "bvtsd_jJqHz3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Car synset 01 hypernyms, hyponyms, meronyms, holonyms, antonym:"
      ],
      "metadata": {
        "id": "bwiuj2_osVf7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s1= wn.synsets('car')[0]\n",
        "print(\"\\ncar.n.01 hypernyms:\")\n",
        "print(s1.hypernyms())\n",
        "print(\"\\ncar.n.01 hyponyms:\")\n",
        "print(s1.hyponyms())\n",
        "print(\"\\ncar.n.01 meronyms:\")\n",
        "print(s1.part_meronyms())\n",
        "print(\"\\ncar.n.01 holonyms:\")\n",
        "print(s1.part_holonyms())\n",
        "print(\"\\ncar.n.01 antonym:\")\n",
        "print(s1.lemmas()[0].antonyms())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2VLOlXPqKcO",
        "outputId": "f43cb35c-f8c4-440d-8de4-64a7e7f6e3d7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "car.n.01 hypernyms:\n",
            "[Synset('motor_vehicle.n.01')]\n",
            "\n",
            "car.n.01 hyponyms:\n",
            "[Synset('ambulance.n.01'), Synset('beach_wagon.n.01'), Synset('bus.n.04'), Synset('cab.n.03'), Synset('compact.n.03'), Synset('convertible.n.01'), Synset('coupe.n.01'), Synset('cruiser.n.01'), Synset('electric.n.01'), Synset('gas_guzzler.n.01'), Synset('hardtop.n.01'), Synset('hatchback.n.01'), Synset('horseless_carriage.n.01'), Synset('hot_rod.n.01'), Synset('jeep.n.01'), Synset('limousine.n.01'), Synset('loaner.n.02'), Synset('minicar.n.01'), Synset('minivan.n.01'), Synset('model_t.n.01'), Synset('pace_car.n.01'), Synset('racer.n.02'), Synset('roadster.n.01'), Synset('sedan.n.01'), Synset('sport_utility.n.01'), Synset('sports_car.n.01'), Synset('stanley_steamer.n.01'), Synset('stock_car.n.01'), Synset('subcompact.n.01'), Synset('touring_car.n.01'), Synset('used-car.n.01')]\n",
            "\n",
            "car.n.01 meronyms:\n",
            "[Synset('accelerator.n.01'), Synset('air_bag.n.01'), Synset('auto_accessory.n.01'), Synset('automobile_engine.n.01'), Synset('automobile_horn.n.01'), Synset('buffer.n.06'), Synset('bumper.n.02'), Synset('car_door.n.01'), Synset('car_mirror.n.01'), Synset('car_seat.n.01'), Synset('car_window.n.01'), Synset('fender.n.01'), Synset('first_gear.n.01'), Synset('floorboard.n.02'), Synset('gasoline_engine.n.01'), Synset('glove_compartment.n.01'), Synset('grille.n.02'), Synset('high_gear.n.01'), Synset('hood.n.09'), Synset('luggage_compartment.n.01'), Synset('rear_window.n.01'), Synset('reverse.n.02'), Synset('roof.n.02'), Synset('running_board.n.01'), Synset('stabilizer_bar.n.01'), Synset('sunroof.n.01'), Synset('tail_fin.n.02'), Synset('third_gear.n.01'), Synset('window.n.02')]\n",
            "\n",
            "car.n.01 holonyms:\n",
            "[]\n",
            "\n",
            "car.n.01 antonym:\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verb consume synsets:"
      ],
      "metadata": {
        "id": "tqS1Y7hasejA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(wn.synsets('eat'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrGyJZ4Fs4Ag",
        "outputId": "737e3000-03ac-476d-895a-faa74d1a9bd6"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Synset('eat.v.01'), Synset('eat.v.02'), Synset('feed.v.06'), Synset('eat.v.04'), Synset('consume.v.05'), Synset('corrode.v.01')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Consume synset definition, examples, and lemmas:"
      ],
      "metadata": {
        "id": "HwMgac66s7OF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s1= wn.synsets('eat')[0]\n",
        "print(s1)\n",
        "print(\"\\ndefinition:\")\n",
        "print(s1.definition())\n",
        "print(\"\\nexamples:\")\n",
        "print(s1.examples())\n",
        "print(\"\\nlemmas:\")\n",
        "print(s1.lemmas())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esQnuJGps8F5",
        "outputId": "8ac517e5-44e4-4f48-e086-c309e8e8521a"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synset('eat.v.01')\n",
            "\n",
            "definition:\n",
            "take in solid food\n",
            "\n",
            "examples:\n",
            "['She was eating a banana', 'What did you eat for dinner last night?']\n",
            "\n",
            "lemmas:\n",
            "[Lemma('eat.v.01.eat')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Consume synset hypernyms up to top:"
      ],
      "metadata": {
        "id": "vfdHzKr7vj4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s1= wn.synsets('eat')[0]\n",
        "print(\"hypernyms up to top:\")\n",
        "hyp = s1.hypernyms()[0]\n",
        "while hyp:\n",
        "  print(hyp)\n",
        "  if hyp.hypernyms():\n",
        "    hyp = hyp.hypernyms()[0]\n",
        "  else:\n",
        "    break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTVlYXB4vs0h",
        "outputId": "74efc518-c8f1-4fe2-cbd0-f893a169a62a"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hypernyms up to top:\n",
            "Synset('consume.v.02')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wordnet synsets for verbs are organized in a less centralized way compared to nouns. There are heirarchical relationships, but these are not necessary, and all the words are not connected. Synsets are only related to words that are closely related and may not have many relations at all."
      ],
      "metadata": {
        "id": "OdaE954kwcYE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "All forms of word using morphy:"
      ],
      "metadata": {
        "id": "ynaRbjqOwiEZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(wn.morphy('eat'))\n",
        "print(wn.morphy('eat', wn.ADJ))\n",
        "print(wn.morphy('eat', wn.VERB))\n",
        "print(wn.morphy('eat', wn.NOUN))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31bMIkF2xCj_",
        "outputId": "c923a235-fd55-4090-9c17-16bf9ffa205b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eat\n",
            "None\n",
            "eat\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wu Palmer similarity is used to find how similar two words are in meaning by comparing how similar their paths are in the wordnet hierarchy from the top to the words. It is not a perfect method but does offer good results, often better than the basic path similarity algorithm. When given the words coffee and tea, it correctly identified how close the words were with a result of 0.888 repeating."
      ],
      "metadata": {
        "id": "EZEnXicKMyjV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "coffeeSet = wn.synsets('coffee')[0]\n",
        "teaSet = wn.synsets('tea')[0]\n",
        "print(wn.wup_similarity(coffeeSet, teaSet))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkBKbN8wI6RQ",
        "outputId": "b27f4a54-345f-479e-ac6c-b3756fc05151"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8888888888888888\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Lesk Algorithm is used for word sense disambiguation, or understanding the specifc meaning of a word with multuple definitions based on the context. After using it on the sentence I provided, it actually gave me an incorrect result, providing the wrong definition for the context. This shows it isn't foolproof."
      ],
      "metadata": {
        "id": "4ManqsunNDn-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import word_tokenize\n",
        "nltk.download('punkt')\n",
        "from nltk.wsd import lesk\n",
        "sent = (\"I need to go back and do the next set of problems\")\n",
        "tokens = word_tokenize(sent)\n",
        "setlesk=(lesk(tokens, 'set', 'n'))\n",
        "print(setlesk)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhTlMocWNHur",
        "outputId": "ddd0f5b5-f7cf-40fc-9b83-aeff5e70e1f7"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synset('stage_set.n.01')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SentiWordNet is built on WordNet and enables sentiment analysis of specific words, assigning them a positive, negative, and objective score based on their connotations. It is useful as it provides more that simply a word's definition and enables more understanding, going past simple word processing. It would help understand the tone of text, which could be used to figure out what type of text is being processed or what tone should be used to respond to an input."
      ],
      "metadata": {
        "id": "9Sr_dIYTPCkP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('sentiwordnet')\n",
        "from nltk.corpus import sentiwordnet as swn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNvVfG4mPEde",
        "outputId": "fc649ad6-b796-452a-ffaf-7328f25b8c79"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package sentiwordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/sentiwordnet.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sw = swn.senti_synsets('escape')\n",
        "for item in sw:\n",
        "    print(item)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2B8w-kb8PoxL",
        "outputId": "99b77766-3093-4c34-ebf3-9cf9c95caecb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<escape.n.01: PosScore=0.0 NegScore=0.0>\n",
            "<escape.n.02: PosScore=0.0 NegScore=0.375>\n",
            "<evasion.n.03: PosScore=0.0 NegScore=0.125>\n",
            "<escape.n.04: PosScore=0.375 NegScore=0.375>\n",
            "<escape.n.05: PosScore=0.0 NegScore=0.0>\n",
            "<escape.n.06: PosScore=0.0 NegScore=0.0>\n",
            "<escape.n.07: PosScore=0.0 NegScore=0.0>\n",
            "<safety_valve.n.01: PosScore=0.0 NegScore=0.0>\n",
            "<escape.v.01: PosScore=0.0 NegScore=0.0>\n",
            "<miss.v.09: PosScore=0.0 NegScore=0.0>\n",
            "<get_off.v.05: PosScore=0.25 NegScore=0.25>\n",
            "<elude.v.02: PosScore=0.0 NegScore=0.125>\n",
            "<escape.v.05: PosScore=0.0 NegScore=0.0>\n",
            "<scat.v.01: PosScore=0.0 NegScore=0.0>\n",
            "<escape.v.07: PosScore=0.0 NegScore=0.0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent2=\"The refugees braved a harrowing journey across the sea to victoriously reach a new land.\"\n",
        "tokens2 = word_tokenize(sent2)\n",
        "for i in tokens2:\n",
        "  syn_list = list(swn.senti_synsets(i))\n",
        "  if syn_list:\n",
        "    print(syn_list[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yL7sBMj2R0kd",
        "outputId": "34aba0c4-6050-461c-99ea-d663c381283c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<refugee.n.01: PosScore=0.0 NegScore=0.0>\n",
            "<weather.v.01: PosScore=0.0 NegScore=0.625>\n",
            "<angstrom.n.01: PosScore=0.0 NegScore=0.0>\n",
            "<harrow.v.01: PosScore=0.0 NegScore=0.0>\n",
            "<journey.n.01: PosScore=0.0 NegScore=0.0>\n",
            "<across.r.01: PosScore=0.0 NegScore=0.0>\n",
            "<sea.n.01: PosScore=0.0 NegScore=0.0>\n",
            "<victoriously.r.01: PosScore=0.25 NegScore=0.0>\n",
            "<range.n.02: PosScore=0.25 NegScore=0.0>\n",
            "<angstrom.n.01: PosScore=0.0 NegScore=0.0>\n",
            "<new.a.01: PosScore=0.375 NegScore=0.0>\n",
            "<land.n.01: PosScore=0.0 NegScore=0.0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Collocations are how often specific words appear together to create a meaning, in the sense that they can be considered a phrase. This is important because it is not purely logical and words with equivalent definitions cannot be swapped out for words in a collocation."
      ],
      "metadata": {
        "id": "avSSDxQPbRi1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from nltk.book import text4\n",
        "print(text4.collocations())\n",
        "text = ' '.join(text4.tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwb9OlcQbtez",
        "outputId": "5e041ada-497c-4bb2-8afe-39aa0ab2f538"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "United States; fellow citizens; years ago; four years; Federal\n",
            "Government; General Government; American people; Vice President; God\n",
            "bless; Chief Justice; one another; fellow Americans; Old World;\n",
            "Almighty God; Fellow citizens; Chief Magistrate; every citizen; Indian\n",
            "tribes; public debt; foreign nations\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "vocab = len(set(text4))\n",
        "hg = text.count('Old World')/vocab\n",
        "h = text.count('Old')/vocab\n",
        "g = text.count('World')/vocab\n",
        "pmi = math.log2(hg / (h * g))\n",
        "print('pmi = ', pmi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czvqq7aEcNgc",
        "outputId": "bbf3b066-75e4-4d2d-b64a-782a4dc5c0a6"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pmi =  8.983886091037398\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The collocation \"Old World\" had a probability of mutual information of 8.98. This means that that collocation had a high incidence rate and is an actual collocation, and the two words come together to create a unique meaning."
      ],
      "metadata": {
        "id": "mFjBLpqrcv7h"
      }
    }
  ]
}